Attention practice:
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/girafe-ai/ml-course/blob/23s_advanced/week03_machine_translation/attention_basics_and_tensorboard.ipynb)

* [seq2seq and attention](https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html)
* [visualizing NMT mechanics of seq2seq with attention](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/)
